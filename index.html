<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Recording canvas+audio example</title>
  </head>
  <body>
    <h1>Web Media Recording</h1>
    <h4>1. Recording data from canvas tag</h4>
    <h4>2. Recording data from audio tag</h4>
    <h4>3. Merging streams from 1 and 2 to generate video with sound</h4>
    <hr />
    <canvas id="canvas" width="600" height="400"></canvas>

    <audio src="./data/viper.mp3" id="audio" controls></audio>
    <hr />
    <br />
    <button id="startButton">Start Recording</button>
    <button id="stopButton">Stop Recording</button>
    <button id="pauseButton">Pause Recording</button>
    <button id="resumeButton">Resume Recording</button>
    <button id="changeaudioButton">Change Audio</button>
    <br />
    <br />
    <button id="previewButton">Preview Video</button>
    <button id="closePreviewButton">Close Preview</button>
    <button id="downloadButton">Download Video</button>

    <script  type="module" src="./dist/ac-recorder.js"></script>
    <script type="module">
      import { ACRecorder } from "./dist/ac-recorder.js";
      let ACR = new ACRecorder(document.querySelector("#audio"), "#canvas");
      ACR.setListeners({
        start: () => {
          console.warn("# recorder - start");
        },
        fail: () => {
          console.warn("# recorder - fail");
        },
        pause: () => {
          console.warn("# recorder - pause");
        },
        resume: () => {
          console.warn("# recorder - resume");
        },
        stop: () => {
          console.warn("# recorder - stop");
        },
      });

      let audios = [
        "./data/viper.mp3",
      ];
      let times = 0;
      let animateRAF = null;

      // Get page elements
      const startButton = document.getElementById("startButton");
      const stopButton = document.getElementById("stopButton");
      const pauseButton = document.getElementById("pauseButton");
      const resumeButton = document.getElementById("resumeButton");
      const previewButton = document.getElementById("previewButton");
      const closePreviewButton = document.getElementById("closePreviewButton");
      const downloadButton = document.getElementById("downloadButton");
      const changeaudioButton = document.getElementById("changeaudioButton");

      // Add event listeners
      startButton.addEventListener("click", () => {
        document
          .querySelector("#audio")
          .play()
          .then((res) => {
            ACR.start()
              .then((res) => {
                drawAudioFrequency(res);
              })
              .catch(console.error);
          });
      });
      pauseButton.addEventListener("click", () => {
        document.querySelector("#audio").pause();
        cancelAnimationFrame(animateRAF)
        ACR.pause();
      });
      resumeButton.addEventListener("click", () => {
        document.querySelector("#audio").play();
        ACR.resume();
      });
      stopButton.addEventListener("click", () => {
        document.querySelector("#audio").pause();
        cancelAnimationFrame(animateRAF)
        ACR.stop();
      });
      previewButton.addEventListener("click", () => {
        ACR.preview();
      });
      closePreviewButton.addEventListener("click", () => {
        ACR.closePreview();
      });
      downloadButton.addEventListener("click", () => {
        ACR.download();
      });
      changeaudioButton.addEventListener("click", () => {
        let url = audios[times % audios.length];
        console.log(times, url);
        ACR.changeAudio(url);
        times++;
      });

      function drawAudioFrequency(context = {}) {
        const { canvas, audioContext, audioSourceNode } = context;
        // Create analyser node
        const analyserNode = audioContext.createAnalyser();
        analyserNode.fftSize = 1024; // [32,32768]

        // Connect the media source node and analyzer node
        audioSourceNode.connect(analyserNode);
        audioSourceNode.connect(audioContext.destination);

         // Create a drawing environment
        const canvasCtx = canvas.getContext("2d");
        const cvsHeight = canvas.height;
        const cvsHalfHeight = cvsHeight / 2;
        const cvsWidth = canvas.width;

        // Coordinate system transformation
        canvasCtx.translate(0, cvsHeight / 2);
        canvasCtx.scale(1, -1);

        function animate() {
           // Get analysis data
          const dataArray = new Uint8Array(analyserNode.frequencyBinCount);
          //   analyserNode.getByteTimeDomainData(dataArray);
          analyserNode.getByteFrequencyData(dataArray);

          // Clear the canvas
          canvasCtx.clearRect(0, -cvsHalfHeight, cvsWidth, cvsHeight);

          // Set the brush style
          canvasCtx.lineWidth = 2;
          canvasCtx.strokeStyle = "#84019a";

          // Start drawing path
          canvasCtx.beginPath();

          // Calculate the position of each data point
          const sliceWidth = (cvsWidth * 1.0) / dataArray.length;
          let x = 0;
          for (let i = 0; i < dataArray.length; i++) {
            const v = dataArray[i] / 128;
            const y = (v * cvsHalfHeight) / 2;

            if (i === 0) {
              canvasCtx.moveTo(x, y);
            } else {
              canvasCtx.lineTo(x, y);
            }

            x += sliceWidth + 1;
          }

          // Stop drawing path
          canvasCtx.stroke();

          // Loop draw
          animateRAF = requestAnimationFrame(animate);
        }

        animate();
      }
    </script>
  </body>
</html>
